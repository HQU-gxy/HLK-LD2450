{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Generator, Iterable, List, Optional, Tuple, TypedDict, cast\n",
    "\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from cv2 import BackgroundSubtractor, BackgroundSubtractorKNN, BackgroundSubtractorMOG2\n",
    "from cv2.typing import MatLike, Size\n",
    "from loguru import logger\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CapProps:\n",
    "    width: int\n",
    "    height: int\n",
    "    fps: float\n",
    "    frame_count: Optional[int] = None\n",
    "\n",
    "\n",
    "def video_cap(\n",
    "        src: str | int) -> Tuple[Generator[MatLike, None, None], CapProps]:\n",
    "    cap = cv2.VideoCapture(src)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    props = CapProps(width, height, fps, frame_count)\n",
    "\n",
    "    def gen():\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            yield frame\n",
    "        cap.release()\n",
    "\n",
    "    return gen(), props\n",
    "\n",
    "\n",
    "# MOT Challenge\n",
    "# PETS09-S2L1\n",
    "def fourcc(*args: str) -> int:\n",
    "    return cv2.VideoWriter_fourcc(*args)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, props = video_cap(\"PETS09-S2L1-raw.mp4\")\n",
    "writer = cv2.VideoWriter(\"PETS09-S2L1-bgsub.mp4\", fourcc(*\"mp4v\"), props.fps, (props.width, props.height), isColor=False)\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "for frame in tqdm(frames, total=props.frame_count):\n",
    "    fgmask = subtractor.apply(frame)\n",
    "    # convert fgmask to RGB for video writer\n",
    "    writer.write(fgmask)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, props = video_cap(\"PETS09-S2L1-raw.mp4\")\n",
    "writer = cv2.VideoWriter(\"PETS09-S2L1-flow_pyr_lk.mp4\", fourcc(*\"mp4v\"),\n",
    "                         props.fps, (props.width, props.height))\n",
    "# use optical flow\n",
    "prev_img_grey: Optional[MatLike] = None\n",
    "prev_pts: Optional[np.ndarray] = None\n",
    "\n",
    "try:\n",
    "    for frame in tqdm(frames, total=props.frame_count):\n",
    "\n",
    "        def go(prev_img_grey: Optional[MatLike], prev_pts: Optional[np.ndarray],\n",
    "               frame: MatLike) -> Tuple[Optional[MatLike],\n",
    "                                        Optional[np.ndarray]]:\n",
    "            # https://docs.opencv.org/4.x/d4/d8c/tutorial_py_shi_tomasi.html\n",
    "            # https://github.com/chuanenlin/optical-flow/blob/master/sparse-solution.py\n",
    "            # https://docs.opencv.org/4.x/db/d7f/tutorial_js_lucas_kanade.html\n",
    "            next_img = frame\n",
    "            pts = cv2.goodFeaturesToTrack(cv2.cvtColor(next_img,\n",
    "                                                       cv2.COLOR_BGR2GRAY),\n",
    "                                          maxCorners=100,\n",
    "                                          qualityLevel=0.3,\n",
    "                                          minDistance=7,\n",
    "                                          blockSize=7)\n",
    "            grey = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "            if prev_img_grey is None:\n",
    "                return grey, pts\n",
    "            # [a 1 2] (a is the features count)\n",
    "            # use ravel to flatten the array\n",
    "            _prev_pts = pts if prev_pts is None else prev_pts\n",
    "            dummy_pts = cast(np.ndarray, None)\n",
    "            pl, st, err = cv2.calcOpticalFlowPyrLK(prev_img_grey, grey,\n",
    "                                                   _prev_pts, dummy_pts)\n",
    "            # status\n",
    "            # output status vector (of unsigned chars); each element of the\n",
    "            # vector is set to 1 if the flow for the corresponding features has\n",
    "            # been found, otherwise, it is set to 0.\n",
    "            # error vector\n",
    "            # output vector of errors; each element of the vector is set to an\n",
    "            # error for the corresponding feature, type of the error measure can\n",
    "            # be set in flags parameter; if the flow wasn't found then the error\n",
    "            # is not defined (use the status parameter to find such cases).\n",
    "            return grey, pl\n",
    "\n",
    "        cur_pts = prev_pts\n",
    "        grey_img, pts = go(prev_img_grey, prev_pts, frame)\n",
    "        assert grey_img is not None\n",
    "        assert pts is not None\n",
    "        if cur_pts is not None and pts is not None:\n",
    "            pts_r = pts.reshape(-1, 2)\n",
    "            cur_pts_r = cur_pts.reshape(-1, 2)\n",
    "            # https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "            for (x0, y0), (x1, y1) in zip(cur_pts_r, pts_r):\n",
    "                x0 = int(x0)\n",
    "                y0 = int(y0)\n",
    "                x1 = int(x1)\n",
    "                y1 = int(y1)\n",
    "                cv2.line(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "        else:\n",
    "            logger.warning(\"no points\")\n",
    "        prev_img_grey = grey_img\n",
    "        prev_pts = pts\n",
    "        writer.write(frame)\n",
    "except KeyboardInterrupt as e:\n",
    "    writer.release()\n",
    "    raise e\n",
    "finally:\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resized_video_cap(\n",
    "    src: str | int,\n",
    "    scale: float = 0.5,\n",
    ") -> Tuple[Generator[MatLike, None, None], CapProps]:\n",
    "    cap = cv2.VideoCapture(src)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * scale)\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * scale)\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    props = CapProps(width, height, fps, frame_count)\n",
    "\n",
    "    def gen():\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            yield frame\n",
    "        cap.release()\n",
    "\n",
    "    return gen(), props\n",
    "\n",
    "\n",
    "frames, props = resized_video_cap(\"PETS09-S2L1-raw.mp4\", 0.5)\n",
    "size = (props.width, props.height)\n",
    "logger.info(f\"size: {size}\")\n",
    "writer = cv2.VideoWriter(\"PETS09-S2L1-dense_flow.mp4\", fourcc(*\"mp4v\"), props.fps,\n",
    "                         size)\n",
    "# use optical flow\n",
    "prev_img_grey: Optional[MatLike] = None\n",
    "\n",
    "try:\n",
    "    for frame in tqdm(frames, total=props.frame_count):\n",
    "\n",
    "        def go(prev_img: Optional[MatLike], frame: MatLike) -> Tuple[\n",
    "                Optional[MatLike], Optional[np.ndarray]]:\n",
    "            next_img = frame\n",
    "            grey = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "            # make type checker happy\n",
    "            dummy_flow = cast(np.ndarray, None)\n",
    "            if prev_img is None:\n",
    "                return grey, None\n",
    "            flow = cv2.calcOpticalFlowFarneback(\n",
    "                prev_img,\n",
    "                grey,\n",
    "                dummy_flow,\n",
    "                pyr_scale=0.5,\n",
    "                levels=3,\n",
    "                winsize=15,\n",
    "                iterations=1,\n",
    "                poly_n=5,\n",
    "                poly_sigma=1.2,\n",
    "                flags=0,\n",
    "            )\n",
    "            return grey, flow\n",
    "\n",
    "        grey_img, flow = go(prev_img_grey, frame)\n",
    "        assert grey_img is not None\n",
    "        if flow is not None:\n",
    "            # Compute the magnitude and angle of the 2D vectors\n",
    "            magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            # Set image hue according to the optical flow direction\n",
    "            mask = np.zeros_like(frame)\n",
    "            mask[..., 1] = 255\n",
    "            mask[..., 0] = angle * 180 / np.pi / 2\n",
    "            # Set image value according to the optical flow magnitude (normalized)\n",
    "            mask[..., 2] = cv2.normalize(magnitude, None, 0, 255,\n",
    "                                         cv2.NORM_MINMAX)\n",
    "            # Convert HSV to RGB (BGR) color representation\n",
    "            rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "            # Resize the frame to match the dimensions of the flow visualization\n",
    "            resized_frame = cv2.resize(frame, (flow.shape[1], flow.shape[0]))\n",
    "            # Combine the flow visualization with the original frame\n",
    "            output = cv2.addWeighted(resized_frame, 0.7, rgb, 1, 0)\n",
    "            # Resize the output back to the original frame size\n",
    "            output = cv2.resize(output, (frame.shape[1], frame.shape[0]))\n",
    "            writer.write(output)\n",
    "        else:\n",
    "            logger.warning(\"no flow\")\n",
    "        prev_img_grey = grey_img\n",
    "except KeyboardInterrupt:\n",
    "    writer.release()\n",
    "    raise e\n",
    "finally:\n",
    "    writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
