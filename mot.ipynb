{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import Sequence, Any, Tuple, Union, List, Dict, Optional, TypeVar, Callable, Iterable, cast\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "data = ak.from_parquet(\"detections.parquet\")\n",
    "display(data.typestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_coords = data[:, :, [\"cX\", \"cY\"]]\n",
    "# use unzip to separate the x and y coordinates\n",
    "cXs, cYs = ak.unzip(detections_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rlabbe/filterpy\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, jit, grad, value_and_grad\n",
    "import numpy as np\n",
    "import jax\n",
    "import chex\n",
    "from jaxtyping import Array, Shaped, Num, Int, Float, Bool, PyTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chex.dataclass\n",
    "class Initiator:\n",
    "    # tentative tracks are temporary tracks maintained by the initiator that\n",
    "    # have been initialized but not yet confirmed\n",
    "    tentative_tracks: Num[Array, \"... 2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filterpy\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# input [x y]\n",
    "# state [x y dx/dt dy/dt]\n",
    "\n",
    "\n",
    "# yapf: disable\n",
    "def F_cv(dt: float|int):\n",
    "    return np.array([[1, 0, dt, 0],\n",
    "                     [0, 1, 0, dt],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "# yapf: enable\n",
    "\n",
    "\n",
    "# yapf: disable\n",
    "def H_cv():\n",
    "    return np.array([[1, 0, 0, 0], \n",
    "                     [0, 1, 0, 0]])\n",
    "# yapf: enable\n",
    "\n",
    "\n",
    "kf = KalmanFilter(4, 2)\n",
    "T = 1.0\n",
    "kf.F = F_cv(T)\n",
    "kf.H = H_cv()\n",
    "kf.R = np.diag([0.75, 0.75])\n",
    "kf.Q = np.diag([0.05, 0.05, 0.05, 0.05])\n",
    "# a simple constant velocity model\n",
    "# let's have a hypothesis of the initial velocity\n",
    "# is 0.05 unit/dt in both x and y directions\n",
    "kf.x = np.array([0, 0, 0.05, 0.05])\n",
    "display(kf.P)\n",
    "kf.predict()\n",
    "# x now becomes x prior\n",
    "display(kf.x)\n",
    "display(kf.P)\n",
    "\n",
    "# kf.update([0.15, 0.15])\n",
    "# x_posterior \n",
    "# when x is updated, it becomes x_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from predict state to measurement\n",
    "kf.x_prior # predicted state\n",
    "# predicted measurement\n",
    "# https://peps.python.org/pep-0465/\n",
    "predicted_measurement = kf.H @ kf.x\n",
    "display(predicted_measurement)\n",
    "# compare the predicted measurement with the actual measurement\n",
    "# with mahalanobis distance\n",
    "actual_measurement = np.array([0.12, 0.12])\n",
    "# or just euclidean distance\n",
    "kf.update(actual_measurement)\n",
    "display(kf.x)\n",
    "display(kf.P)\n",
    "display(kf.mahalanobis)\n",
    "# use mahalanobis distance as a loss function to determine the best match\n",
    "# Hungarian algorithm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html\n",
    "# when we get a successively detected object, we can move it into the confirmed tracks\n",
    "# and remove it from the tentative tracks\n",
    "# Well, it's more like two GNNs, one for the tentative tracks and one for the confirmed tracks\n",
    "# cascaded GNN, interesting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract out the Kalman filter\n",
    "# by motion model (state)\n",
    "# and measurement model\n",
    "\n",
    "# https://github.com/sisl/GaussianFilters.jl\n",
    "# not consider Input/External effect\n",
    "from jaxtyping import jaxtyped\n",
    "from typeguard import typechecked\n",
    "\n",
    "\n",
    "@chex.dataclass\n",
    "class LinearMotionNoInputModel:\n",
    "    F: Num[Array, \"n n\"]\n",
    "    Q: Num[Array, \"n n\"]\n",
    "\n",
    "\n",
    "@chex.dataclass\n",
    "class LinearMeasurementModel:\n",
    "    H: Num[Array, \"m n\"]\n",
    "    R: Num[Array, \"m m\"]\n",
    "\n",
    "\n",
    "Measurement = Num[Array, \"m\"]\n",
    "\n",
    "\n",
    "# a belief of Gaussian\n",
    "@chex.dataclass\n",
    "class GaussianState:\n",
    "    x: Num[Array, \"n\"]\n",
    "    P: Num[Array, \"n n\"]\n",
    "\n",
    "\n",
    "@jaxtyped(typechecker=typechecked)\n",
    "def _predict(\n",
    "    state: GaussianState,\n",
    "    motion_model: LinearMotionNoInputModel,\n",
    ") -> GaussianState:\n",
    "    x = state.x\n",
    "    P = state.P\n",
    "    F = motion_model.F\n",
    "    Q = motion_model.Q\n",
    "    assert x.shape[0] == F.shape[\n",
    "        0], \"state and transition model are not compatible\"\n",
    "    assert F.shape[0] == F.shape[1], \"transition model is not square\"\n",
    "    assert F.shape[0] == Q.shape[\n",
    "        0], \"transition model and noise model are not compatible\"\n",
    "    x_priori = F @ x\n",
    "    P_priori = F @ P @ F.T + Q\n",
    "    return GaussianState(x=x_priori, P=P_priori)\n",
    "\n",
    "\n",
    "@chex.dataclass\n",
    "class PosterioriResult:\n",
    "    # updated state\n",
    "    state: GaussianState\n",
    "    innovation: Num[Array, \"m\"]\n",
    "    posteriori_measurement: Num[Array, \"m\"]\n",
    "    mahalanobis_distance: Num[Array, \"m\"]\n",
    "    # post-fit residual\n",
    "    # y = z - H @ x_posteriori\n",
    "\n",
    "\n",
    "@jaxtyped(typechecker=typechecked)\n",
    "def update(\n",
    "    measurement: Measurement,\n",
    "    state: GaussianState,\n",
    "    measure_model: LinearMeasurementModel,\n",
    ") -> PosterioriResult:\n",
    "    x = state.x\n",
    "    P = state.P\n",
    "    H = measure_model.H\n",
    "    R = measure_model.R\n",
    "    assert x.shape[0] == H.shape[\n",
    "        1], \"state and measurement model are not compatible\"\n",
    "    assert H.shape[0] == R.shape[0], \"measurement model is not square\"\n",
    "    assert H.shape[0] == R.shape[1], \"measurement model is not square\"\n",
    "    z = measurement\n",
    "    inv = jnp.linalg.inv\n",
    "    # innovation\n",
    "    # the priori measurement residual\n",
    "    y = z - H @ x\n",
    "    # innovation covariance\n",
    "    S = H @ P @ H.T + R\n",
    "    # Kalman gain\n",
    "    K = P @ H.T @ inv(S)\n",
    "    # posteriori state\n",
    "    x_posteriori = x + K @ y\n",
    "    # dummy identity matrix\n",
    "    I = jnp.eye(P.shape[0])\n",
    "    # posteriori covariance\n",
    "    I_KH = I - K @ H\n",
    "    P_posteriori = I_KH @ P @ I_KH.T + K @ R @ K.T\n",
    "    posteriori_state = GaussianState(x=x_posteriori, P=P_posteriori)\n",
    "    posteriori_measurement = H @ x_posteriori\n",
    "    return PosterioriResult(\n",
    "        state=posteriori_state,\n",
    "        innovation=y,\n",
    "        posteriori_measurement=posteriori_measurement,\n",
    "        mahalanobis_distance=jnp.sqrt(y.T @ inv(S) @ y),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(\n",
    "    v_x: float,\n",
    "    v_y: float,\n",
    "    dt: float,\n",
    "    q: float,\n",
    "    r: float,\n",
    ") -> Tuple[\n",
    "        LinearMotionNoInputModel,\n",
    "        LinearMeasurementModel,\n",
    "        GaussianState,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Create a constant velocity model with no input\n",
    "    \n",
    "    Args:\n",
    "    v_x: initial velocity in x direction\n",
    "    v_y: initial velocity in y direction\n",
    "    dt: time interval\n",
    "    q: process noise\n",
    "    r: measurement noise\n",
    "\n",
    "    Returns:\n",
    "    motion_model: motion model\n",
    "    measure_model: measurement model\n",
    "    state: initial state\n",
    "    \"\"\"\n",
    "    # yapf: disable\n",
    "    F = jnp.array([[1, 0, dt, 0],\n",
    "                        [0, 1, 0, dt],\n",
    "                        [0, 0, 1, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "    H = jnp.array([[1, 0, 0, 0],\n",
    "                        [0, 1, 0, 0]])\n",
    "    # yapf: enable\n",
    "    Q = q * jnp.eye(4)\n",
    "    R = r * jnp.eye(2)\n",
    "    P = jnp.eye(4)\n",
    "    motion_model = LinearMotionNoInputModel(F=F, Q=Q)\n",
    "    measure_model = LinearMeasurementModel(H=H, R=R)\n",
    "    state = GaussianState(x=jnp.array([0, 0, v_x, v_y]), P=P)\n",
    "    return motion_model, measure_model, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_model, me_model, st = cv_model(0.05, 0.05, 1.0, 0.05, 0.75)\n",
    "\n",
    "# predict\n",
    "new_st = _predict(st, mo_model)\n",
    "# update\n",
    "res = update(jnp.array([0.12, 0.12]), new_st, me_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_ak_record(dict_like: Dict[str, Any] | Any) -> ak.Record:\n",
    "#     return ak.Record(dict_like.__dict__)\n",
    "s = ak.Array([st.__dict__, new_st.__dict__])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxtyped(typechecker=typechecked)\n",
    "def outer_distance(x: Num[Array, \"a 2\"], y: Num[Array,\n",
    "                                                \"b 2\"]) -> Num[Array, \"a b\"]:\n",
    "    \"\"\"\n",
    "    Here's equivalent python code:\n",
    "    \n",
    "    ```python\n",
    "    res = jnp.empty((x.shape[0], y.shape[0]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[0]):\n",
    "            # res[i, j] = jnp.linalg.norm(x[i] - y[j])\n",
    "            res = res.at[i, j].set(jnp.linalg.norm(x[i] - y[j]))\n",
    "    return res\n",
    "    ```\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    `outer product <https://en.wikipedia.org/wiki/Outer_product>`_\n",
    "    \"\"\"\n",
    "\n",
    "    @jit\n",
    "    def go(x, y):\n",
    "        x_expanded = x[:, None, :]\n",
    "        y_expanded = y[None, :, :]\n",
    "        diff = y_expanded - x_expanded\n",
    "        return jnp.linalg.norm(diff, axis=-1)\n",
    "\n",
    "    return go(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Generator, TypedDict\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html\n",
    "# https://github.com/google/jax/issues/10403\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "AKArray = ak.Array\n",
    "\n",
    "# register the JAX backend\n",
    "ak.jax.register_and_check()  # type: ignore\n",
    "\n",
    "\n",
    "@chex.dataclass\n",
    "class Tracking:\n",
    "    id: int\n",
    "    state: GaussianState\n",
    "    survived_time_steps: int\n",
    "    missed_time_steps: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrackerParams:\n",
    "    dt: float = 1.0\n",
    "    cov_threshold: float = 4.0\n",
    "    tentative_mahalanobis_threshold: float = 10.0\n",
    "    confirm_mahalanobis_threshold: float = 10.0\n",
    "    forming_tracks_euclidean_threshold: float = 25.0\n",
    "    survival_steps_threshold: int = 3\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    \"\"\"\n",
    "    A simple GNN tracker\n",
    "    \"\"\"\n",
    "    _last_measurements: Float[Array, \"... 2\"] = jnp.empty((0, 2),\n",
    "                                                          dtype=jnp.float32)\n",
    "    _tentative_tracks: list[Tracking] = []\n",
    "    _confirmed_tracks: list[Tracking] = []\n",
    "    _last_id: int = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self._last_measurements = jnp.array([], dtype=jnp.float32)\n",
    "        self._tentative_tracks = []\n",
    "        self._confirmed_tracks = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _predict(tracks: list[Tracking], dt: float = 1.0):\n",
    "        return [\n",
    "            Tracking(\n",
    "                id=track.id,\n",
    "                state=_predict(track.state, Tracker.motion_model(dt=dt)),\n",
    "                survived_time_steps=track.survived_time_steps,\n",
    "                missed_time_steps=track.missed_time_steps,\n",
    "            ) for track in tracks\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _data_associate_and_update(\n",
    "            measurements: Float[Array, \"... 2\"],\n",
    "            tracks: list[Tracking],\n",
    "            distance_threshold: float = 3) -> Float[Array, \"... 2\"]:\n",
    "        \"\"\"\n",
    "        Match tracks with measurements and update the tracks\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        [in] measurements: Float[\"a 2\"]\n",
    "        [in,out] tracks: Tracking[\"b\"]\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        return \n",
    "            Float[\"... 2\"] the unmatched measurements\n",
    "        \n",
    "        Effect\n",
    "        ----------\n",
    "        find the best match by minimum Mahalanobis distance, please note that I assume the state has been predicted\n",
    "        \"\"\"\n",
    "        if len(tracks) == 0:\n",
    "            return measurements\n",
    "\n",
    "        def _update(measurement: Float[Array, \"a 2\"], tracking: Tracking):\n",
    "            return update(measurement, tracking.state,\n",
    "                          Tracker.measurement_model())\n",
    "\n",
    "        def outer_posteriori(\n",
    "                measurements: Float[Array, \"a 2\"],\n",
    "                tracks: list[Tracking]) -> list[list[PosterioriResult]]:\n",
    "            \"\"\"\n",
    "            calculate the outer posteriori for each measurement and track\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            [in] measurements: Float[\"a 2\"]\n",
    "            [in] tracks: Tracking[\"b\"]\n",
    "\n",
    "            Returns\n",
    "            ----------\n",
    "            PosterioriResult[\"a b\"]\n",
    "            \"\"\"\n",
    "            return [[\n",
    "                _update(measurement, tracking) for measurement in measurements\n",
    "            ] for tracking in tracks]\n",
    "\n",
    "        def posteriori_to_mahalanobis(\n",
    "                posteriori: list[list[PosterioriResult]]\n",
    "        ) -> Float[Array, \"a b\"]:\n",
    "            \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            [in] posteriori: PosterioriResult[\"a b\"]\n",
    "\n",
    "            Returns\n",
    "            ----------\n",
    "            Float[\"a b\"]\n",
    "            \"\"\"\n",
    "            return jnp.array(\n",
    "                [[r_m.mahalanobis_distance for r_m in p_t] for p_t in posteriori\n",
    "                ],\n",
    "                dtype=jnp.float32)\n",
    "\n",
    "        posteriors = outer_posteriori(measurements, tracks)\n",
    "        distances = posteriori_to_mahalanobis(posteriors)\n",
    "        row, col = linear_sum_assignment(np.array(distances))\n",
    "        row = jnp.array(row)\n",
    "        col = jnp.array(col)\n",
    "\n",
    "        def to_be_deleted() -> Generator[Tuple[int, int], None, None]:\n",
    "            for i, j in zip(row, col):\n",
    "                post: PosterioriResult = posteriors[i][j]\n",
    "                if post.mahalanobis_distance > distance_threshold:\n",
    "                    yield i, j\n",
    "\n",
    "        for i, j in to_be_deleted():\n",
    "            row = row[row != i]\n",
    "            col = col[col != j]\n",
    "\n",
    "        for i, j in zip(row, col):\n",
    "            track: Tracking = tracks[i]\n",
    "            post: PosterioriResult = posteriors[i][j]\n",
    "            track.state = post.state\n",
    "            track.survived_time_steps += 1\n",
    "            tracks[i] = track\n",
    "\n",
    "        for i, track in enumerate(tracks):\n",
    "            if i not in row:\n",
    "                # reset the survived time steps once missed\n",
    "                track.missed_time_steps += 1\n",
    "                tracks[i] = track\n",
    "        # remove measurements that have been matched\n",
    "        left_measurements = jnp.delete(measurements, col, axis=0)\n",
    "        return left_measurements\n",
    "\n",
    "    def _tracks_from_past_measurements(self,\n",
    "                                       measurements: Float[Array, \"... 2\"],\n",
    "                                       dt: float = 1.0,\n",
    "                                       distance_threshold: float = 3.0):\n",
    "        \"\"\"\n",
    "        consume the last measurements and create tentative tracks from them\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        mutate self._tentative_tracks and self._last_measurements\n",
    "        \"\"\"\n",
    "        if self._last_measurements.shape[0] == 0:\n",
    "            self._last_measurements = measurements\n",
    "            return\n",
    "        distances = outer_distance(self._last_measurements, measurements)\n",
    "        row, col = linear_sum_assignment(distances)\n",
    "        row = jnp.array(row)\n",
    "        col = jnp.array(col)\n",
    "\n",
    "        def to_be_deleted() -> Generator[Tuple[int, int], None, None]:\n",
    "            for i, j in zip(row, col):\n",
    "                euclidean_distance = distances[i, j]\n",
    "                if euclidean_distance > distance_threshold:\n",
    "                    yield i, j\n",
    "\n",
    "        for i, j in to_be_deleted():\n",
    "            row = row[row != i]\n",
    "            col = col[col != j]\n",
    "\n",
    "        for i, j in zip(row, col):\n",
    "            coord = measurements[j]\n",
    "            vel = (coord - self._last_measurements[i]) / dt\n",
    "            s = jnp.concatenate([coord, vel])\n",
    "            state = GaussianState(x=s, P=jnp.eye(4))\n",
    "            track = Tracking(id=self._last_id,\n",
    "                             state=state,\n",
    "                             survived_time_steps=0,\n",
    "                             missed_time_steps=0)\n",
    "            self._last_id += 1\n",
    "            self._tentative_tracks.append(track)\n",
    "        # update the last measurements with the unmatched measurements\n",
    "        self._last_measurements = jnp.delete(measurements, col, axis=0)\n",
    "\n",
    "    def _transfer_tentative_to_confirmed(self,\n",
    "                                        survival_steps_threshold: int = 3):\n",
    "        \"\"\"\n",
    "        transfer tentative tracks to confirmed tracks\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        mutate self._tentative_tracks and self._confirmed_tracks in place\n",
    "        \"\"\"\n",
    "        for i, track in enumerate(self._tentative_tracks):\n",
    "            if track.survived_time_steps > survival_steps_threshold:\n",
    "                self._confirmed_tracks.append(track)\n",
    "                self._tentative_tracks.pop(i)\n",
    "\n",
    "    @staticmethod\n",
    "    def _track_cov_deleter(tracks: list[Tracking], cov_threshold: float = 4.0):\n",
    "        \"\"\"\n",
    "        delete tracks with covariance trace greater than threshold\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        [in,out] tracks: list[Tracking]\n",
    "        cov_threshold: float\n",
    "            the threshold of the covariance trace\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        mutate tracks in place\n",
    "        \"\"\"\n",
    "        for i, track in enumerate(tracks):\n",
    "            # https://numpy.org/doc/stable/reference/generated/numpy.trace.html\n",
    "            if jnp.trace(track.state.P) > cov_threshold:\n",
    "                tracks.pop(i)\n",
    "\n",
    "    def next_measurements(self, measurements: Float[Array, \"... 2\"],\n",
    "                          params: TrackerParams):\n",
    "        self._confirmed_tracks = self._predict(self._confirmed_tracks,\n",
    "                                               params.dt)\n",
    "        self._tentative_tracks = self._predict(self._tentative_tracks,\n",
    "                                               params.dt)\n",
    "        left_ = self._data_associate_and_update(\n",
    "            measurements, self._confirmed_tracks,\n",
    "            params.confirm_mahalanobis_threshold)\n",
    "        left = self._data_associate_and_update(\n",
    "            left_, self._tentative_tracks,\n",
    "            params.tentative_mahalanobis_threshold)\n",
    "        self._transfer_tentative_to_confirmed(params.survival_steps_threshold)\n",
    "        self._tracks_from_past_measurements(\n",
    "            left, params.dt, params.forming_tracks_euclidean_threshold)\n",
    "        self._track_cov_deleter(self._tentative_tracks, params.cov_threshold)\n",
    "        self._track_cov_deleter(self._confirmed_tracks, params.cov_threshold)\n",
    "\n",
    "    @property\n",
    "    def confirmed_tracks(self):\n",
    "        return self._confirmed_tracks\n",
    "\n",
    "    @staticmethod\n",
    "    def motion_model(dt: float = 1,\n",
    "                     q: float = 0.05) -> LinearMotionNoInputModel:\n",
    "        \"\"\"\n",
    "        a constant velocity motion model\n",
    "        \"\"\"\n",
    "        # yapf: disable\n",
    "        F = jnp.array([[1, 0, dt, 0],\n",
    "                            [0, 1, 0, dt],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "        # yapf: enable\n",
    "        Q = q * jnp.eye(4)\n",
    "        return LinearMotionNoInputModel(F=F, Q=Q)\n",
    "\n",
    "    @staticmethod\n",
    "    def measurement_model(r: float = 0.75) -> LinearMeasurementModel:\n",
    "        # yapf: disable\n",
    "        H = jnp.array([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0]])\n",
    "        # yapf: enable\n",
    "        R = r * jnp.eye(2)\n",
    "        return LinearMeasurementModel(H=H, R=R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_measurements() -> Generator[Float[Array, \"... 2\"], None, None]:\n",
    "    for m_cXs, m_cYs in zip(cXs, cYs):\n",
    "        nxs = m_cXs.to_numpy()\n",
    "        nys = m_cYs.to_numpy()\n",
    "        xs = jnp.array(nxs)\n",
    "        ys = jnp.array(nys)\n",
    "        yield jnp.column_stack([xs, ys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker()\n",
    "\n",
    "tenative_histories: list[list[Tracking]] = []\n",
    "confirmed_histories: list[list[Tracking]] = []\n",
    "\n",
    "params = TrackerParams(\n",
    "    cov_threshold=25.0,\n",
    "    tentative_mahalanobis_threshold=50.0,\n",
    "    confirm_mahalanobis_threshold=25.0,\n",
    "    forming_tracks_euclidean_threshold=20,\n",
    "    dt=1.0,\n",
    "    survival_steps_threshold=6,\n",
    ")\n",
    "\n",
    "for measurement in gen_measurements():\n",
    "    m = jnp.array(measurement)\n",
    "    tracker.next_measurements(m, params)\n",
    "    tenative_histories.append(tracker._tentative_tracks.copy())\n",
    "    confirmed_histories.append(tracker._confirmed_tracks.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cv2\n",
    "from cv2.typing import MatLike\n",
    "from loguru import logger\n",
    "\n",
    "@dataclass\n",
    "class CapProps:\n",
    "    width: int\n",
    "    height: int\n",
    "    fps: float\n",
    "    frame_count: Optional[int] = None\n",
    "\n",
    "def fourcc(*args: str) -> int:\n",
    "    return cv2.VideoWriter_fourcc(*args)  # type: ignore\n",
    "\n",
    "def video_cap(\n",
    "        src: str | int) -> Tuple[Generator[MatLike, None, None], CapProps]:\n",
    "    cap = cv2.VideoCapture(src)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    props = CapProps(width, height, fps, frame_count)\n",
    "\n",
    "    def gen():\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            yield frame\n",
    "        cap.release()\n",
    "\n",
    "    return gen(), props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, props = video_cap(\"PETS09-S2L1-raw.mp4\")\n",
    "writer = cv2.VideoWriter(\"PETS09-S2L1-tracking.mp4\",\n",
    "                         fourcc(*\"mp4v\"),\n",
    "                         props.fps, (props.width, props.height),\n",
    "                         isColor=True)\n",
    "\n",
    "class RawDataDict(TypedDict):\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "    area: float\n",
    "    cX: int\n",
    "    cY: int\n",
    "\n",
    "display(props)\n",
    "\n",
    "try:\n",
    "    colors = np.random.randint(0, 255, size=(1024, 3))\n",
    "    for frame, tentative_tracks, confirmed_tracks, raws in zip(\n",
    "            frames, tenative_histories, confirmed_histories, data): # type: ignore\n",
    "        for raw in raws:\n",
    "            x, y, w, h, area, cX, cY = raw.x, raw.y, raw.w, raw.h, raw.area, raw.cX, raw.cY\n",
    "            cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # generate a random color map for each track\n",
    "        for track in tentative_tracks:\n",
    "            x, y = track.state.x[:2]\n",
    "            color_ = colors[track.id]\n",
    "            color = tuple(color_.tolist())\n",
    "            # cv.rectangle(frame, (int(x - 5), int(y - 5), 10, 10), color, -1)\n",
    "        for track in confirmed_tracks:\n",
    "            x, y = track.state.x[:2]\n",
    "            color_ = colors[track.id]\n",
    "            color = tuple(color_.tolist())\n",
    "            cv.circle(frame, (int(x), int(y)), 5, color, -1)\n",
    "        writer.write(frame)\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "finally:\n",
    "    writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
